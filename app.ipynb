{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "981e6733",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf4c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\satya\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Dense, Input, LSTM, add\n",
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5728c89",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c788de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\satya\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "import tensorflow\n",
    "new_model = tensorflow.keras.models.load_model(r\"D:\\Mechine Learning\\Project\\Image Captioning\\best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf98b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 35)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 4096)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 35, 256)              2171648   ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 4096)                 0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 35, 256)              0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  1048832   ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 256)                  525312    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 256)                  0         ['dense[0][0]',               \n",
      "                                                                     'lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  65792     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 8483)                 2180131   ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5991715 (22.86 MB)\n",
      "Trainable params: 5991715 (22.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774352eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pickle.load(open(r\"D:\\Mechine Learning\\Project\\Image Captioning\\features.pkl\", \"rb\"))\n",
    "tokenizer = pickle.load(open(r\"D:\\Mechine Learning\\Project\\Image Captioning\\tokenizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2c394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1\n",
    "max_length = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75343bef",
   "metadata": {},
   "source": [
    "## Genrate Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbac075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d784e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'start'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        # encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad the sequence\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        # get index with high probability\n",
    "        yhat = np.argmax(yhat)\n",
    "        # convert index to word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        # stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        # append word as input for generating next word\n",
    "        in_text += \" \" + word\n",
    "        # stop if we reach end tag\n",
    "        if word == 'end':\n",
    "            break\n",
    "      \n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210bd22",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "539fd0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\satya\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16()\n",
    "# restructure the model\n",
    "vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d4b5b",
   "metadata": {},
   "source": [
    "# Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e6ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDyc2kCi4_X0T8gCeyXSjv6YudKP7YuIww\"\n",
    "gemini_api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "genai.configure(api_key = gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e973b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e31555a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(input_image):\n",
    "    data = Image.fromarray(input_image)\n",
    "    temp_img_path = \"temp_input_img.jpg\"\n",
    "    data.save(temp_img_path)\n",
    "    image = load_img(temp_img_path, target_size=(224, 224))\n",
    "    os.remove(temp_img_path)\n",
    "    image = np.array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    feature = vgg_model.predict(image, verbose=0)\n",
    "    caption = predict_caption(new_model, feature, tokenizer, max_length)\n",
    "    caption = caption[6:len(caption)-3]\n",
    "    #caption = \" \".join(list(filter(lambda x:x not in [\"start\", \"end\"], caption.split())))\n",
    "    #return caption\n",
    "    #for i in range(len(caption)):\n",
    "    #    time.sleep(0.03)\n",
    "    #    yield caption[0:i+1]\n",
    "    response = model.generate_content(f'''Write a short story in 5 lines in a creative way with the caption\n",
    "                                        generated by my Image captioning model.\n",
    "                                        caption of my image :{caption}\n",
    "                                        Now generate story in simple english.''')\n",
    "    story = response.text\n",
    "    \n",
    "    #return caption, story\n",
    "    for i in range(len(story)):\n",
    "        if(len(caption)>=i):\n",
    "            time.sleep(0.03)\n",
    "            yield caption[0:i+1], \"\"\n",
    "        else:\n",
    "            for i in range(len(story)):\n",
    "                time.sleep(0.03)\n",
    "                yield caption, story[0:i+1]\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f137f",
   "metadata": {},
   "source": [
    "# Voice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3970e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gtts import gTTS\n",
    "from pygame import mixer\n",
    "\n",
    "text = '''In the quaint streets of a small town. \n",
    "            where they shared dreams and secrets. With every shared laugh and stolen glance. '''\n",
    "\n",
    "def listen_to_story(text):\n",
    "    tts = gTTS(text=text, lang='en', slow=False, tld=\"ca\")\n",
    "    file = \"output_audio.mp3\"\n",
    "    tts.save(file)\n",
    "    mixer.init()\n",
    "    mixer.music.load(file)\n",
    "    mixer.music.play()\n",
    "    while mixer.music.get_busy():\n",
    "        continue\n",
    "    mixer.quit()\n",
    "    os.remove(file)\n",
    "# listen_to_story(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa3c1b",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf39fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = '''\n",
    "    .gradio-container {\n",
    "       /*background-color:#9a8c98;*/\n",
    "       background-image:url(\"https://www.csshero.org/wp-content/uploads/2016/07/hohenschwangau-532864_1920.jpg\");\n",
    "       background-size:cover;\n",
    "       /*background: linear-gradient(#e66465, #9198e5);*/\n",
    "       \n",
    "       \n",
    "    }\n",
    "    .svelte-13hsdno{\n",
    "        color:white;\n",
    "    }\n",
    "    .sub-title{\n",
    "        display:flex;\n",
    "        justify-content:center;\n",
    "        margin:0px;\n",
    "    }\n",
    "    .scroll{\n",
    "        width:30%;\n",
    "        font-weight:800;\n",
    "        \n",
    "    }\n",
    "    .title{\n",
    "        font-size:30px;\n",
    "        text-align: center;\n",
    "        font-weight:900;\n",
    "    }\n",
    "    button>.secondary{\n",
    "        width:50%;\n",
    "        color:red;\n",
    "        \n",
    "    }\n",
    "   \n",
    "'''\n",
    "description_html = \"\"\"<div class='sub-title'><marquee class='scroll' behavior=\"scroll\" direction=\"right\">Let your picture speak..</marquee></div>\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9277250",
   "metadata": {},
   "source": [
    "# Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1960d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Monochrome(), title=\"Caption Generator\", css=css) as demo:\n",
    "    gr.Row(\n",
    "        gr.Markdown(\"<b>Caption Generator</b>\", elem_classes='title'),\n",
    "        gr.Markdown(description_html)\n",
    "    )\n",
    "#     gr.Markdown(\"Upload Image\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            inp1 = gr.Image()\n",
    "            btn = gr.Button(\"Run\")\n",
    "        with gr.Column():\n",
    "            out1 = gr.Textbox(label=\"Caption\", text_align=\"center\")\n",
    "            out2 = gr.TextArea(label=\"Story\", text_align=\"center\", lines=5)\n",
    "            btn1 = gr.Button(\"Listen Story\")\n",
    "    btn.click(fn=process_image, inputs=inp1, outputs=[out1, out2])\n",
    "    btn1.click(fn=listen_to_story, inputs=out2)\n",
    "    gr.Row(gr.ClearButton([inp1, out1, out2]))\n",
    "    gr.Examples([[r\"D:\\Mechine Learning\\Project\\Image Captioning\\archive\\Images\\109202801_c6381eef15.jpg\"],\n",
    "                [r\"D:\\Mechine Learning\\Project\\Image Captioning\\archive\\Images\\1002674143_1b742ab4b8.jpg\"],\n",
    "               [r\"D:\\Mechine Learning\\Project\\Image Captioning\\archive\\Images\\44129946_9eeb385d77.jpg\"],\n",
    "               [r\"D:\\Mechine Learning\\Project\\Image Captioning\\archive\\Images\\138705546_be7a6845dd.jpg\"],\n",
    "               [r\"D:\\Mechine Learning\\Project\\Image Captioning\\archive\\Images\\128912885_8350d277a4.jpg\"]\n",
    "               ], inputs=[inp1])\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3c37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382391a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
